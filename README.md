# denoise-python

**Speech Denoising with Full- and Sub-band LSTM Network**

---

## ğŸš€ Projenin AmacÄ±

Bu proje, konuÅŸma sinyallerindeki gÃ¼rÃ¼ltÃ¼yÃ¼ kaldÄ±rmak iÃ§in **FullSubNet** (Full- and Sub-band LSTM) tabanlÄ± bir derin Ã¶ÄŸrenme modelini PyTorch ile uygulamaktadÄ±r.
Matlab'da geliÅŸtirilmiÅŸ prototipin Pythonâ€™a Ã§evrimi; veri hazÄ±rlama (STFT tabanlÄ± mask Ã¼retimi), model mimarisi, eÄŸitim ve Ã§Ä±karÄ±m (inference) adÄ±mlarÄ±nÄ± iÃ§erir. AyrÄ±ca **veri artÄ±rma** (data augmentation) olarak:

* **Rastgele SNR** (Signal-to-Noise Ratio)
* **Mixture of Noises** (farklÄ± gÃ¼rÃ¼ltÃ¼ kaynaklarÄ±nÄ± karÄ±ÅŸtÄ±rma)

yaklaÅŸÄ±mlarÄ±, modelin genelleme performansÄ±nÄ± artÄ±rmak iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r.

---

## ğŸ“ Proje Dizini (KlasÃ¶r YapÄ±sÄ±)

```
denoise-python/
â”œâ”€ .gitignore
â”œâ”€ README.md
â”œâ”€ train.py                 # EÄŸitim (training) scripti
â”œâ”€ inference.py             # BÃ¼tÃ¼n uzunlukta ses dosyalarÄ± iÃ§in Ã§Ä±karÄ±m (inference) scripti
â”œâ”€ models/
â”‚   â””â”€ denoise_model.py     # FullSubNet mimarisi ve yardÄ±mcÄ± katmanlar
â”œâ”€ utils/
â”‚   â”œâ”€ ci_mask.py           # cIRM (Complex Ideal Ratio Mask) hesaplama fonksiyonu
â”‚   â”œâ”€ speech_features.py   # DNSDataset: STFT + mask Ã¼retimi + veri artÄ±rma
â”‚   â”œâ”€ generate_synthetic_data.py  # Sentetik temiz/gaussian gÃ¼rÃ¼ltÃ¼ verisi Ã¼retimi Ã¶rneÄŸi
â”‚   â”œâ”€ split_audio.py       # Uzun WAV dosyalarÄ±nÄ± eÅŸit parÃ§alara (chunks) bÃ¶lme
â”‚   â””â”€ resample_and_pad.py  # Ses dosyalarÄ±nÄ± 8 kHzâ€™e dÃ¼ÅŸÃ¼rme ve pad/truncate iÅŸlemleri
â”œâ”€ data/
â”‚   â”œâ”€ clean_fullband/      # Temiz konuÅŸma sinyalleri (WAV)
â”‚   â”œâ”€ noise_fullband/      # GÃ¼rÃ¼ltÃ¼ sinyalleri (WAV)
â”‚   â””â”€ test/                # EÄŸitim dÄ±ÅŸÄ±nda kullanÄ±lan test WAV dosyalarÄ±
â”œâ”€ checkpoints/             # KÃ¼Ã§Ã¼k Ã§aplÄ± eÄŸitim iÃ§in kaydedilen modeller
â”œâ”€ checkpoints_big/         # BÃ¼yÃ¼k veri setiyle eÄŸitimde kaydedilen modeller
â””â”€ output/                  # Ä°nference sonucu oluÅŸturulan denoised WAV dosyalarÄ±
```

> **Not:**
>
> * `data/clean_fullband/` altÄ±na 8 kHzâ€™e yeniden Ã¶rneklenmiÅŸ (resample) temiz konuÅŸma dosyalarÄ±nÄ±z olmalÄ±dÄ±r.
> * `data/noise_fullband/` altÄ±na 8 kHzâ€™e dÃ¼ÅŸÃ¼rÃ¼lmÃ¼ÅŸ gÃ¼rÃ¼ltÃ¼ WAVâ€™leri yerleÅŸtirilir.
> * `data/test/` klasÃ¶rÃ¼nde, Ã§Ä±karÄ±m (inference) aÅŸamasÄ± iÃ§in gÃ¼rÃ¼ltÃ¼lÃ¼ veya uzun test WAVâ€™ler bulunur.

---

## ğŸ“¦ BaÄŸÄ±mlÄ±lÄ±klar (Dependencies)

AÅŸaÄŸÄ±daki paketler ve araÃ§lar Ã¶nceden kurulmuÅŸ olmalÄ±dÄ±r:

* Python â‰¥ 3.8
* PyTorch â‰¥ 1.9 (CUDA destekli: `torch.cuda.is_available() == True`)
* torchaudio
* numpy
* soundfile (torchaudio arka ucu olarak)
* Git (proje yÃ¶netimi iÃ§in)

```bash
# Ã–rnek conda kurulumu:
conda create -n denoise-env python=3.9
conda activate denoise-env
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
pip install numpy soundfile
```

---

## ğŸ“Š Model Mimarisi: FullSubNet

```
FullSubNet:
  â”œâ”€ Input: [B, 1, F=257, T=time_steps]
  â”œâ”€ Full-Band BÃ¶lÃ¼mÃ¼:
  â”‚   â”œâ”€ PadLayer: T â†’ T+2
  â”‚   â”œâ”€ â€£ LSTM1 (num_hidden_fb)
  â”‚   â”œâ”€ â€£ LSTM2 (num_hidden_fb)
  â”‚   â”œâ”€ â€£ FullyConnected(Freq â†’ F)
  â”‚   â””â”€ â€£ ReLU + Unsqueeze(2) â†’ [B, F=257, 1, T+2]
  â”‚
  â”œâ”€ Sub-Band BÃ¶lÃ¼mÃ¼:
  â”‚   â”œâ”€ UnfoldLayer: Sliding window (Â±15 frekans komÅŸusu) â†’ [B, F=257, 31, T]
  â”‚   â”œâ”€ Pad (time eksenine 1er Ã¶rnek ekle) â†’ T+2
  â”‚   â”œâ”€ reshapeâ†’[B*F, T+2, 31]
  â”‚   â”œâ”€ LSTM3 (num_hidden_sb)
  â”‚   â”œâ”€ LSTM4 (num_hidden_sb)
  â”‚   â”œâ”€ FC2 (â†’ 2 real/imag mask boyutu)
  â”‚   â””â”€ RelabelLayer & FinalLayer â†’ [B, 2, 257, T]
  â”‚
  â””â”€ Ã‡Ä±ktÄ±: [B, 2, 257, T] (real+imag cIRM mask)
```

* **F** = 257 (1-257 arasÄ± tek taraflÄ± FFT frekans sayÄ±sÄ±)
* **T** = `time_steps` (Ã¶rneÄŸin 92 frame)
* **num\_hidden\_fb** = 768 (Full-band LSTM gizli boyutu)
* **num\_hidden\_sb** = 512 (Sub-band LSTM gizli boyutu)
* **--time\_steps** parametresi, STFT Ã§Ä±ktÄ± zaman Ã§erÃ§evesi sayÄ±sÄ±dÄ±r. Ä°nference ve eÄŸitimde bu aynÄ± deÄŸerle Ã§alÄ±ÅŸmalÄ±dÄ±r.

DetaylÄ± katmanlar ve ileri-besleme (**forward**) akÄ±ÅŸÄ±, `models/denoise_model.py` dosyasÄ±nda Python sÄ±nÄ±fÄ± olarak tanÄ±mlanmÄ±ÅŸtÄ±r.

---

## ğŸ”„ Veri HazÄ±rlama ve Data Augmentation

### 1. Temiz / GÃ¼rÃ¼ltÃ¼ DosyalarÄ±nÄ±n HazÄ±rlanmasÄ±

* `data/clean_fullband/` klasÃ¶rÃ¼ne konuÅŸma WAV dosyalarÄ±nÄ±zÄ± koyun. TÃ¼m dosyalar 8 kHz olmalÄ± (eÄŸer 48 kHz ise `utils/resample_and_pad.py` ile 8 kHzâ€™e dÃ¼ÅŸÃ¼rebilirsiniz).
* `data/noise_fullband/` klasÃ¶rÃ¼nde Ã§eÅŸitli gÃ¼rÃ¼ltÃ¼ WAV dosyalarÄ± bulunsun (Ã¶rneÄŸin: trafik, vantilatÃ¶r, yaÄŸmur, kalabalÄ±k vb.). Yine 8 kHzâ€™e resample edildiklerinden emin olun.

### 2. Chunkâ€™lama (Split Audio)

EÄŸer elinizde uzun tek bir WAV varsa (Ã¶rneÄŸin 1 saatlik kayÄ±t), otomatik olarak 3 saniyelik (24 000 Ã¶rnek) parÃ§alara bÃ¶lmek iÃ§in:

```bash
python utils/split_audio.py --input_dir data/clean_fullband --output_dir data/clean_fullband
python utils/split_audio.py --input_dir data/noise_fullband --output_dir data/noise_fullband
```

* Bu script, dosyalarÄ± `*_chunk01.wav`, `*_chunk02.wav` â€¦ ÅŸeklinde 3 saniyelik segmentlere bÃ¶ler.
* BÃ¶ylece hem clean hem de noise dosyalarÄ±nÄ±z doÄŸrudan 3 s/24 000 Ã¶rnek uzunluÄŸunda olur.

### 3. Sentetik Veri Ãœretme (Opsiyonel)

Sabit frekanslÄ± (sinÃ¼s) iÅŸaretler veya Gaussian gÃ¼rÃ¼ltÃ¼ gibi basit Ã¶rnekleri `utils/generate_synthetic_data.py` scriptiyle oluÅŸturabilirsiniz:

```bash
python utils/generate_synthetic_data.py
```

* Ã‡Ä±ktÄ±da `data/clean_fullband/sine_200Hz.wav`, `sine_400Hz.wav`, â€¦ gibi sinÃ¼s sinyalleri
* `data/noise_fullband/noise_1.wav`, â€¦ gibi beyaz gÃ¼rÃ¼ltÃ¼ dosyalarÄ± elde edilir.
* Bu basit veriler, modelin ilk prototip eÄŸitimleri veya test amaÃ§lÄ± kullanÄ±labilir.

### 4. DNSDataset Ä°Ã§inde Veri ArtÄ±rma (Data Augmentation)

`speech_features.py` dosyasÄ±ndaki `DNSDataset` sÄ±nÄ±fÄ±nda iki Ã¶nemli augmentation adÄ±mÄ± bulunur:

1. **Mixture of Noises**

   * Her `__getitem__` Ã§aÄŸrÄ±sÄ±nda rastgele iki farklÄ± noise dosyasÄ± seÃ§ilir (`random.sample`)
   * Bu ikisinin eÅŸit aÄŸÄ±rlÄ±klÄ± ortalamasÄ± alÄ±nÄ±r:

     ```python
     combined_noise_np = (noise_seg1 + noise_seg2) / 2.0
     ```

2. **Rastgele SNR**

   * SeÃ§ilebilecek dB deÄŸerleri: `[-5, 0, 5, 10]` (Ã¶rnek)
   * Rastgele bir `snr_db` seÃ§ilir, lineer Ã¶lÃ§eÄŸe Ã§evrilir:

     ```python
     snr_lin = 10 ** (snr_db / 10)
     ```
   * â€œcleanâ€ ve â€œcombined\_noiseâ€ gÃ¼Ã§leri hesaplanÄ±r ve `noise_scaled_np = combined_noise_np * sqrt(clean_power / (noise_power * snr_lin))` formÃ¼lÃ¼yle Ã¶lÃ§eklenir.
   * Son olarak `noisy_np = clean_np + noise_scaled_np` oluÅŸturulur.

BÃ¶ylece her eÄŸitim adÄ±mÄ± (batch) iÃ§in farklÄ± SNR seviyesinde, farklÄ± gÃ¼rÃ¼ltÃ¼ karÄ±ÅŸÄ±mlarÄ± kullanÄ±larak zengin bir veri kÃ¼mesi sunulur.

---

## ğŸ—ï¸ Dataset YapÄ±sÄ±

```
data/
â”œâ”€ clean_fullband/
â”‚   â”œâ”€ 001_chunk01.wav
â”‚   â”œâ”€ 001_chunk02.wav
â”‚   â”œâ”€ 002_chunk01.wav
â”‚   â””â”€ â€¦ (3 saniyelik temiz parÃ§alara bÃ¶lÃ¼nmÃ¼ÅŸ WAV dosyalarÄ±)
â”‚
â”œâ”€ noise_fullband/
â”‚   â”œâ”€ 004_chunk01.wav
â”‚   â”œâ”€ 004_chunk02.wav
â”‚   â”œâ”€ 005_chunk01.wav
â”‚   â””â”€ â€¦ (3 saniyelik gÃ¼rÃ¼ltÃ¼ parÃ§alara bÃ¶lÃ¼nmÃ¼ÅŸ WAV dosyalarÄ±)
â”‚
â””â”€ test/
    â”œâ”€ test_003.wav          # 3 snâ€™lik test dosyasÄ±
    â””â”€ test_long_003.wav     # >3 sn: inference iÃ§in Ã¶rnek uzun WAV
```

* `clean_fullband/` ve `noise_fullband/` iÃ§indeki her dosya 8000 Hz, 16 bit, tek kanallÄ± (mono), **3 saniye** (24 000 Ã¶rnek) uzunluÄŸundadÄ±r.
* EÄŸitim: her `__getitem__` Ã§aÄŸrÄ±sÄ±nda `i` indeksli clean vs. rastgele seÃ§ilen 2 noise birleÅŸtirilir.
* Test: `data/test/` altÄ±nda hem kÄ±sa (3 saniye) hem de uzun (Ã¶rneÄŸin 10 saniye) dosyalar bulunur. Uzun dosya, â€œarbitrary length inferenceâ€ (isteÄŸe baÄŸlÄ± uzunlukta inference) koduyla parÃ§alara bÃ¶lÃ¼nerek iÅŸlenir.

---

## ğŸ“ˆ Model EÄŸitimi (Training)

### KÃ¼Ã§Ã¼k Ã–lÃ§ekli EÄŸitim

```bash
python train.py \
  --data_dir data \
  --batch_size 8 \
  --epochs 15 \
  --lr 5e-4 \
  --time_steps 92 \
  --checkpoint_dir checkpoints
```

* `--data_dir data`
* `--batch_size 8`
* `--epochs 15`
* `--lr 5e-4`
* `--time_steps 92` (3 saniye iÃ§in \~92 STFT frame)
* `--checkpoint_dir checkpoints`

### BÃ¼yÃ¼k Ã–lÃ§ekli EÄŸitim (Data Augmentation + Uzun Epoch)

```bash
python train.py \
  --data_dir data \
  --batch_size 16 \
  --epochs 100 \
  --lr 5e-4 \
  --time_steps 92 \
  --checkpoint_dir checkpoints_big \
  --log_interval 10 \
  --patience 10
```

* `--batch_size 16` (GPU belleÄŸine baÄŸlÄ± olarak ayarlanabilir)
* `--epochs 100`
* `--log_interval 10` (Her 10 adÄ±mda bir validation raporu)
* `--patience 10` (Validation loss 10 epoch iyileÅŸmediyse erken durdurma)
* En dÃ¼ÅŸÃ¼k validation loss iÃ§in `checkpoints_big/best_epoch_{i}.pth` dosyasÄ± kaydedilir.

---

## ğŸ¯ Ã‡Ä±karÄ±m (Inference)

### KÄ±sa (3 s) Test DosyasÄ±

```bash
python inference.py \
  --model_path checkpoints_big/best_epoch_11.pth \
  --input_wav data/test/test_003.wav \
  --output_wav output/denoised_test_003.wav \
  --sample_rate 8000 \
  --time_steps 92
```

* `--model_path`: EÄŸitilmiÅŸ model aÄŸÄ±rlÄ±ÄŸÄ± (`.pth`).
* `--input_wav`: GÃ¼rÃ¼ltÃ¼lÃ¼ test WAV (tam 3 saniye).
* `--output_wav`: Denoise edilmiÅŸ WAVâ€™Ä±n kaydedileceÄŸi yol.
* `--sample_rate 8000`, `--time_steps 92` (eÄŸitimle aynÄ± STFT frame sayÄ±sÄ±).

### Uzun (Arbitrary-Length) Test DosyasÄ±

```bash
python inference.py \
  --model_path checkpoints_big/best_epoch_11.pth \
  --input_wav data/test/test_long_003.wav \
  --output_wav output/denoised_test_long_003.wav \
  --sample_rate 8000 \
  --time_steps 92
```

* Uzun sinyali, modelin kabul ettiÄŸi `time_steps` (92 frame) boyutunda parÃ§alara bÃ¶lerek her parÃ§a iÃ§in Ã§Ä±karÄ±m yapar.
* ArdÄ±ndan â€œoverlap-addâ€ yÃ¶ntemiyle parÃ§alarÄ± birleÅŸtirip tek bir denoised Ã§Ä±kÄ±ÅŸ Ã¼retir.

---

## ğŸ”§ Parametre AÃ§Ä±klamalarÄ±

| ArgÃ¼man            | AÃ§Ä±klama                                                                   |
| ------------------ | -------------------------------------------------------------------------- |
| `--data_dir`       | `clean_fullband/` ve `noise_fullband/` altÄ±ndaki verilerin kÃ¶k klasÃ¶rÃ¼.    |
| `--batch_size`     | GPUâ€™daki bellek durumuna gÃ¶re ayarlanabilir.                               |
| `--epochs`         | Maksimum eÄŸitim dÃ¶ngÃ¼sÃ¼ sayÄ±sÄ±.                                            |
| `--lr`             | BaÅŸlangÄ±Ã§ Ã¶ÄŸrenme oranÄ± (learning rate).                                   |
| `--time_steps`     | STFTâ€™Ä±n zaman ekseni Ã§erÃ§eve sayÄ±sÄ± (3 s iÃ§in â‰ˆ 92).                       |
| `--checkpoint_dir` | EÄŸitim sÄ±rasÄ±nda kaydedilecek model aÄŸÄ±rlÄ±klarÄ±nÄ±n dizini.                 |
| `--log_interval`   | KaÃ§ iterationâ€™da bir validation raporu verileceÄŸi (training scriptâ€™te).    |
| `--patience`       | Validation loss belirli epoch sayÄ±sÄ± boyunca iyileÅŸmediyse erken durdurma. |

---

## ğŸ“œ Lisans ve KatkÄ±da Bulunma

* Bu proje, eÄŸitim ve araÅŸtÄ±rma amaÃ§lÄ± **MIT LisansÄ±** altÄ±nda yayÄ±nlanmÄ±ÅŸtÄ±r.
* KatkÄ±da bulunmak, hata bildirmek veya iyileÅŸtirme Ã¶nerileri sunmak iÃ§in GitHub Issues sayfasÄ±nÄ± kullanabilirsiniz.
